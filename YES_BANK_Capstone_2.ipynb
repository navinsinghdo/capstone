{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navinsinghdo/capstone/blob/main/YES_BANK_Capstone_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  YES bank stock closing price prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Share market is simply the market place where multiple traders and investors buy and sell shares of different companies. The primary crux of share market is that people try to buy share in a lower prce and sell it when the price increases, thus marking a profit. Reason to use ML in share price prediction: Since the existence of share market, the share price analysis have always been predicted by humans, manually. They used different techniques which included many mathematical and economics formulae, etc. which required a lot of human calculation, thus have human limitation. Thus, as the computation capacity of computers have increased and high piwer ML algorithms are available, it's often better to take help of ML models in predicting the price of share and identify pattern.\n",
        "\n",
        "In the data set I recieved, I have features of open, high, low and close, where I had to find a pattern to predict the close using open, high and low.\n",
        "\n",
        "I started my analysis with EDA, where I found how exactly the data was distributed. Independent parameters were skewed, so I adjusted them with log transformation. I also made plots to see how the dependent variable was varying with different independent variables.\n",
        "\n",
        "I also made a dataframe for VIF score, even when the vif was high, I decided not to drop any feature to see the accuracy I get. (Note: I later decided not to drop any feature finally as I am getting a high accuracy).\n",
        "\n",
        "I started building the models, I used LR, Ridge and Lasso and also XGBRegression. I got the highest accuracy in XGBRegression with least mean squared error. Thus, I am selecting XGBRegression as my final model with 0.991 Rsquare."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stockâ€™s closing price of the month"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from numpy import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yes_df = pd.read_csv('/content/drive/MyDrive/AlmaBetter/Yesbank.csv')"
      ],
      "metadata": {
        "id": "v-62mPAHd16d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "yes_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "yes_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "yes_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "yes_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "yes_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "import missingno as msno\n",
        "msno.bar(yes_df)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set is about open, high , low and close price of yes bank share price. It does not have any duplicate rows neither it have any null."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset \n",
        "\n",
        "yes_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "yes_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date - Date of record\n",
        "\n",
        "Open - Opening price\n",
        "\n",
        "High - Highest price in the day\n",
        "\n",
        "Low - Lowest price in the day\n",
        "\n",
        "Close - Closing price\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in yes_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",yes_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "#1. The data is already in data frame form, thus it is analysis ready. \n",
        "#2. There is no missing or duplicated, thus cleaning is not required.\n",
        "#3. Methods like one-hot-encoding, etc. is not required either.\n",
        "\n",
        "#Converting column of date to datetime object, it will allow us better analysis. \n",
        "\n",
        "from datetime import datetime #importing lib for changing\n",
        "yes_df['Date'] = yes_df['Date'].apply(lambda x: datetime.strptime(x , '%b-%y'))"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making data ML model ready by splitting dependent and independent variable.\n",
        "\n",
        "x = yes_df.drop(columns = ['Close' , 'Date'])  #X is independent variable, or feature. Dropping the target variable and data as it's not a feature. \n",
        "y = yes_df['Close'] # closing price is out target."
      ],
      "metadata": {
        "id": "CtF6JIzYjlZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only manipulation required here was to change column of date into datetime object.\n",
        "I additionally made the data ML model ready by splitting it into dependent and independent variable.\n",
        "The data do not have missing rows, duplicate columns, etc."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1\n",
        "\n",
        "Share closing price trend."
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "plt.figure(figsize= (20,7))\n",
        "plt.title('Yes bank Share closing price')\n",
        "sns.lineplot(x='Date' , y = 'Close' , data = yes_df)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I want to see a continous data over a long period of time, line plot is the best option as it's easy to understand."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As clear by graph, the share price was increasing from 2014-2018, then it had a sharp decline. It increased again in 2019, but declined again."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Not Applicable here."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2\n",
        "\n",
        "Distibution plot of our target variable, i.e. closing price/close."
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "plt.figure(figsize = (20,7))\n",
        "sns.distplot(yes_df['Close'] , kde= 'True')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distplots are the best way to look into distribution of any variable, specially continous variable. Thus, I used it."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As visible here, the data is skewed towards right, thus right skewed distribution. I will apply log transformation to make it more uniform."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Not applicable here."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n",
        "\n",
        "Distributiuon of independent variable"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization \n",
        "\n",
        "plt.figure(figsize = (20,7))\n",
        "\n",
        "#Creating different subplots. \n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "sns.distplot(yes_df['Open'], color = 'Red')\n",
        "plt.title('Open price distribution')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "sns.distplot(yes_df['High'] , color = 'Green')\n",
        "plt.title('Highest price of day distribution')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "sns.distplot(yes_df['Low'] , color = 'Blue')\n",
        "plt.title('Lowest price of day distribution')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I am checking distribution of different variables here, I used a distplot inside a subplot. Subplot is good to look into multiple distribution, or graphs in one place."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the above distribution looks right-skewed thus we will later apply log transformation to introduce some normalization."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NA here."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4\n",
        "\n",
        "variation of our target(closing price) w.r.t. all our independent variable/feature, Regression plot is also added(best fit line)"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "plt.figure(figsize = (20,7))\n",
        "\n",
        "#creating different subplot again. \n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "sns.regplot(x='Open' , \n",
        "            y='Close',\n",
        "            data = yes_df , color = 'Red')\n",
        "plt.title('Open vs close')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "sns.regplot(x='High' , \n",
        "            y='Close',\n",
        "            data = yes_df , color = 'Green')\n",
        "plt.title('High vs close')\n",
        "\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "sns.regplot(x='Low' , \n",
        "            y='Close',\n",
        "            data = yes_df , color = 'Blue')\n",
        "plt.title('Low vs Close')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regplot is good to see how variables varry with each other, but constructing a regression line. I have used them inside a subplot to view them all in one place."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All variables varies with our dependent variable that is close. It varies lineary with some outliers."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NA here."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5\n",
        "\n",
        "Box plot"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "plt.figure(figsize = (20,7))\n",
        "plt.title('Box plot')\n",
        "sns.boxplot(data = yes_df)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot is used to see 5-number summary of the data, thus used it."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a number of outliers. The median of data looks very close to each other."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NA here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6\n",
        "\n",
        "Correlation Heatmap"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "\n",
        "sns.heatmap(yes_df.corr(), annot = True ,  cmap=sns.diverging_palette(20, 220, n=200))"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmaps are good to look into corelation, thus I used it."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows a very high corelation. We will handle it in feature engineering section."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7\n",
        "\n",
        "Pair Plot"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "sns.pairplot(yes_df)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seaborn pair plot is used to view pairplot thus I have used a pair plot. It helps us in understanding how different pairs of variables varies along with each other and distribution."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the variables changes lineary and are dependent on each other."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handling Missing Values & Missing Value Imputation\n",
        "#The data have no missing values thus it is not required."
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# I am considering the outliers of data is due to natural causes of stock market, thus I am not deleting them or using any other outliers handling method. I will \n",
        "# run different ML algorithms and only handle outliers in case the score of models is lower."
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking VIF of independent variables."
      ],
      "metadata": {
        "id": "NcXp7t87VNy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calculate_vif(X):\n",
        "\n",
        "  # calculating VIF\n",
        "  vif =pd.DataFrame()\n",
        "  vif[\"variables\"] = X.columns\n",
        "  vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X. shape[1])]\n",
        "\n",
        "  return(vif)"
      ],
      "metadata": {
        "id": "GR5AItZYVRe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_vif(yes_df[[i for i in yes_df.describe().columns if i not in ['Date', 'Close']]])"
      ],
      "metadata": {
        "id": "WWs1T7KQVY9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the VIF is very high, I am deciding not to drop any of the features as all of them are important in this particular use case. I will run all the model, and if I do not get expected accuracy, I will revisit this section."
      ],
      "metadata": {
        "id": "g8mc-6ZvVd7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,7))\n",
        "sns.distplot(np.log(yes_df['Close']))\n",
        "plt.title('Distribution of Close Price', fontsize=15)\n",
        "plt.xlabel('Closing Price', fontsize= 15)\n",
        "plt.ylabel('Density', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eC_i9_tUV7Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,7))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.distplot(np.log(yes_df['Open']), color = 'Red')\n",
        "plt.title('Distribution', fontsize=18)\n",
        "plt.xlabel('Open', fontsize= 16)\n",
        "plt.ylabel('Density', fontsize=14)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.distplot(np.log(yes_df['High']), color = 'Green')\n",
        "plt.title('Distribution', fontsize=18)\n",
        "plt.xlabel('High', fontsize= 16)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.distplot(np.log(yes_df['Low']), color = 'Blue')\n",
        "plt.title('Distribution', fontsize=18)\n",
        "plt.xlabel('Low', fontsize= 16)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-TUEJ37JV7CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore #importing necessary lib. \n",
        "# data transformation\n",
        "x = x.apply(zscore)\n",
        "y = np.log10(y)"
      ],
      "metadata": {
        "id": "Gi0a9pMuV62u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The different feature of data was skewed in this data frame, as seen earlier in visualization section. I have applied log transformation to make it more normal"
      ],
      "metadata": {
        "id": "hPmOWNLJWVqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x_train , x_test , y_train , y_test = train_test_split( x, y , test_size = 0.2 , random_state = 1) #splitting data."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "80, 20 is common data splitting ratio and I am using the same."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1\n",
        "\n",
        "Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "regressor = LinearRegression() #Setting up regressor model\n",
        "\n",
        "# Fit the Algorithm\n",
        "regressor.fit(x_train , y_train) #fitting model\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = regressor.predict(x_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "gfQio6_UXheA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.score(x_train , y_train)"
      ],
      "metadata": {
        "id": "PqAVs2krXhWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scoring test\n",
        "\n",
        "regressor.score(x_test , y_test)"
      ],
      "metadata": {
        "id": "m6boSk_XXhL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a DF for testing data.\n",
        "\n",
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "uI2p52Z8Xg_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I am visualizing predicted vs actual close price.\n",
        "# Actual Price vs predicted price plot.\n",
        "# Actual Price vs predicted price plot.\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Close Price for LR', fontsize =15)\n",
        "plt.legend([\"Predicted\",\"Actual\"], fontsize=14)\n",
        "plt.xlabel('No of Test Data', fontsize= 15)\n",
        "plt.ylabel('Closing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "HP121aESX2NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the independent variable.\n",
        "\n",
        "Here, different features(independent variables) are taken, multiplied by best possible coefficient(identified by gradient descant) and added together to predict dependent variable."
      ],
      "metadata": {
        "id": "CIVsYRYlYF6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Performance:\n",
        "print(\"MSE value :\", round(mean_squared_error(y_test, y_pred), 4))\n",
        "print(\"RMSE value :\", round(math.sqrt(mean_squared_error(y_test, y_pred)), 4)) \n",
        "print(\"MAE value :\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE value :\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"r2 score :\", round(r2_score(y_test, y_pred),4))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "\n",
        "Ridge Regression"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge #importing lib"
      ],
      "metadata": {
        "id": "mBPwOUsjYjNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Ridge (alpha = 0.1) #setting model as Ridge\n",
        "\n",
        "model.fit(x_train , y_train) #fitting model"
      ],
      "metadata": {
        "id": "HZnGJ1FLYjJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_train , y_train) #training score"
      ],
      "metadata": {
        "id": "a-gxNyr6YjG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_test , y_test) #testing scor"
      ],
      "metadata": {
        "id": "WsqmqSrpYjED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred\n",
        "\n",
        "#(using same variable names as other models to avoid confusion and time)"
      ],
      "metadata": {
        "id": "iMJq1tgrYjBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "VKPtxXrhYi_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price In Ridge'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "Mb4PGXhmYi8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in Ridge Regression', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "no6tdKVLYi6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge is one of regularization technique used for linear regression. It adds penality in regression function and helps in handling overfitting large data sets"
      ],
      "metadata": {
        "id": "EqoBsrE4ZKLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Performance :\n",
        "\n",
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import GridSearchCV #importing lib\n",
        "model = Ridge()\n",
        "parameters = {'alpha': [1e-15, 1e-13, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20, 30, 40, 45, 50, 55, 60, 100]}\n",
        "model_cv = GridSearchCV(model, parameters, scoring = 'neg_mean_squared_error', cv=3)\n",
        "# Fit the Algorithm\n",
        "model_cv.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = model_cv.predict(x_test)"
      ],
      "metadata": {
        "id": "oCQUxop6ZXg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" The Best Fit Alpha Value is found out to be :\", model_cv.best_params_['alpha'])\n",
        "print(\" The negative MSE(mean squared error) score is :\", round(model_cv.best_score_, 3))"
      ],
      "metadata": {
        "id": "Ex3nRtsoZXSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price In Ridge with cross - validation'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "Wp8PBaO5Zm14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in Ridge Regression with cross - validation', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "jO8-keXUZmpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used grid search CV to find the optimal parameter as it's best possible way here to identify best parameter."
      ],
      "metadata": {
        "id": "dGJ2PMMyaMXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance :\n",
        "\n",
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "ynZb26I3aXhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R2 score of of Ridge was 0.82 while after cross validation it is 0.81, thus there is no improvement"
      ],
      "metadata": {
        "id": "LAXSMLfnabRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R2 is a measure of the goodness of fit of a model. In regression, the R2 coefficient of determination is a statistical measure of how well the regression predictions approximate the real data points. An R2 of 1 indicates that the regression predictions perfectly fit the data."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3\n",
        "\n",
        "Lasso Regression"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.linear_model import Lasso \n",
        "model = Lasso(alpha=0.005, max_iter = 3000)\n",
        "model.fit(x_train, y_train) \n",
        "# Fit the Algorithm\n",
        "model.score(x_train , y_train) #training score\n",
        "# Predict on the model\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred\n",
        "\n",
        "#(using same variable names as other models to avoid confusion and time)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_train , y_train) #training score"
      ],
      "metadata": {
        "id": "wk3ysDFQdNy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_test , y_test) #testing score"
      ],
      "metadata": {
        "id": "irZ9XrzjdNvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price In Lasso'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "ITYhtH02dNtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in Lasso Regression', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "niAKfHQ-dNqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "Just like ridge regression it is another regularization technique used for linear regression, it used magnitute of coefficien"
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Performance :\n",
        "\n",
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "parameters ={'alpha': [1e-15, 1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "model_cv = GridSearchCV(model, parameters,scoring = 'neg_mean_squared_error', cv = 3, return_train_score=True)\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_cv.fit(x_train, y_train) \n",
        "\n",
        "# Predict on the model\n",
        "y_pred = model_cv.predict(x_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" The best Fit alpha value is found out to be :\", round(model_cv.best_params_['alpha'], 4))\n",
        "print(\" The negative mean squared error is : \", round(model_cv. best_score_,4))"
      ],
      "metadata": {
        "id": "P4TxwitveM8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in Lasso Regression with Cross-validation', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "yvUKEewReSgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used gridsearchcv to find the best parameter."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "dCEmCe5lekBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While R2 score of lasso was 0.82, after gridsearch, the R2 score is 0.819, only a very slight increase.Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HVk0kFvtyTYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Model - 4\n",
        "\n",
        "Elastic Net regression"
      ],
      "metadata": {
        "id": "-fmXAh7RyXuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "model = ElasticNet(alpha=0.1,l1_ratio=0.5)\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "LJihq3_lyU2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_train , y_train) #training score"
      ],
      "metadata": {
        "id": "RPK3o8MzyW5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_test , y_test) #testing score"
      ],
      "metadata": {
        "id": "SCt-1pwYyWiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred\n",
        "\n",
        "#(using same variable names as other models to avoid confusion and time)"
      ],
      "metadata": {
        "id": "BaosQtYWyVva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "eWZaCAt7Skaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price In Elastic Net regression'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "IMaLeVMRSkXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in Elastic Net regression', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)\n",
        "     "
      ],
      "metadata": {
        "id": "k941sZW8SkUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "Elastic net linear regression uses the penalties from both the lasso and ridge techniques to regularize regression models. The technique combines both the lasso and ridge regression methods by learning from their shortcomings to improve the regularization of statistical models"
      ],
      "metadata": {
        "id": "mkXfCfCzyTIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance :\n",
        "\n",
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "mlXLpQwVTONi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "Using Cross-validation in Elastic net regression"
      ],
      "metadata": {
        "id": "2-Uh9H-UTXjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-Parameter Tuning\n",
        "\n",
        "model = ElasticNet()\n",
        "parameters = {'alpha':[1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100],'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8,1,2]}\n",
        "model_cv= GridSearchCV(model,parameters,scoring='neg_mean_squared_error',cv=3)"
      ],
      "metadata": {
        "id": "EWr86PLiTT1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cv.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "jFoNJ5TvTTyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha and L1 ratio value is found out to be :\" ,model_cv.best_params_['alpha'], model_cv.best_params_['l1_ratio'])\n",
        "print(\"The negative mean squared error for is: \", round(model_cv.best_score_,3))"
      ],
      "metadata": {
        "id": "TjBtqsiWTTvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_cv.predict(x_test)\n",
        "y_pred\n",
        "\n",
        "#(using same variable names as other models to avoid confusion and time)"
      ],
      "metadata": {
        "id": "eB2P4koPTTtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "6wrjOTgXTTqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price In Elastic net regression with Cross-validation'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "2PDeOrr-TToM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in Lasso Regression with Cross-validation', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "wKHnkFtKTTly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which hyperparameter optimization technique have you used and why?\n",
        "\n",
        "Here I have used gridsearchcv, I used it to find the best parameter."
      ],
      "metadata": {
        "id": "U9R2eZ7XUGx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart"
      ],
      "metadata": {
        "id": "LB6Bkr2FUJDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance :\n",
        "\n",
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "rvdZfr4TTTjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R2 score od elastic net regressor was 0.79 while after cross validation it is 0.819, hence it have improved"
      ],
      "metadata": {
        "id": "0BkTFSCoUVBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Model - 5\n",
        "\n",
        "XG Boost regression"
      ],
      "metadata": {
        "id": "awNYvixdUelh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "#Importing lib, setting model and training. \n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "model = XGBRegressor()\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "nGcTxnK1TTgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_train , y_train) #training score"
      ],
      "metadata": {
        "id": "YCh_0X19TTeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_test , y_test) #testing score"
      ],
      "metadata": {
        "id": "i34BQTDdTTbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred\n",
        "\n",
        "#(using same variable names as other models to avoid confusion and time)"
      ],
      "metadata": {
        "id": "F0hxKP4uTTZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "BQc3h1N0TTWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(y_test)\n",
        "test_df.rename(columns = {'close' : 'Actual closing price'} , inplace = True)\n",
        "test_df['Predicted closing price In XGBoost'] = y_pred\n",
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "_MKClC0SVBft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(10**(y_pred),color='red')\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.suptitle('Actual Vs Predicted Value in XG Boost', fontsize= 15)\n",
        "plt.legend(['Predicted','Actual'], fontsize = 15)\n",
        "plt.xlabel('No of Yes Bank Test Data', fontsize = 15)\n",
        "plt.ylabel('Crossing Price', fontsize= 15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "ovpb905KVBcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "XGBoost is a popular and efficient open-source implementation of the gradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm, which attempts to accurately predict a target variable by combining the estimates of a set of simpler, weaker models."
      ],
      "metadata": {
        "id": "BeMslOqWVOLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance :\n",
        "\n",
        "# Test Performance\n",
        "print(\"MSE score:\", round(mean_squared_error (y_test, y_pred), 4))\n",
        "print(\"RMSE score:\", round(math.sqrt(mean_squared_error (y_test, y_pred)), 4))\n",
        "print(\"MAE score:\", round(mean_absolute_error(y_test, y_pred), 4))\n",
        "print(\"MAPE score:\", round(mean_absolute_percentage_error(y_test, y_pred), 4))\n",
        "print(\"R2 score:\", round(r2_score(y_test, y_pred), 4))"
      ],
      "metadata": {
        "id": "WKgAD-gBVBaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Which Evaluation metrics did you consider for a positive business impact and why?\n",
        "\n",
        "During my analysis, I have given most importance to R2 score. Our target here was to determine the close price as accurately as it can get.\n",
        "\n",
        "R2 is a measure of the goodness of fit of a model. In regression, the R2 coefficient of determination is a statistical measure of how well the regression predictions approximate the real data points. An R2 of 1 indicates that the regression predictions perfectly fit the data. In simple terms, the better the model is able to accurately predict our dependent variable, the closer it is to 1.\n",
        "\n",
        "Given our target objective, R2 is best evaluation metric to generate a positive buisness impace as it will help our measure how good our models are doing."
      ],
      "metadata": {
        "id": "ET3n2z_CVb19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Which ML model did you choose from the above created models as your final prediction model and why?\n",
        "\n",
        "I already have performance data for all models, I am writing a function to test and write all models performance and writing it in one dataframe."
      ],
      "metadata": {
        "id": "47cyeGbnViR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making a function for mean absolute % error. \n",
        "\n",
        "def mape(actual , pred):\n",
        "  actual , pred = np.array(actual) , np.array(pred)\n",
        "  return np.mean(np.abs((actual - pred) / actual) )*100"
      ],
      "metadata": {
        "id": "hv1UB6JSVBYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Makeing a function to calculate performance parameters and put them in a dataframe..\n",
        "\n",
        "def model_score(x_train , y_train , x_test , y_test):\n",
        "  df_columns = []\n",
        "  df = pd.DataFrame(columns = df_columns) #Creating dataframe to store performance metrics.\n",
        "\n",
        "  model1 = LinearRegression()\n",
        "  model2 = Ridge (alpha = 0.1)\n",
        "  model3 = Lasso(alpha=0.005, max_iter = 3000)\n",
        "  model4 = XGBRegressor()\n",
        "\n",
        "  i = 0\n",
        "  models = [model1, model2 , model3 , model4 ]\n",
        "\n",
        "  for model in models:\n",
        "    model.fit(x_train , y_train)\n",
        "\n",
        "    y_pred_train = model.predict(x_train)\n",
        "    y_pred_test = model.predict(x_test)\n",
        "\n",
        " #Computing evaluation metrics\n",
        "    train_accuracy=model.score(x_train,y_train)\n",
        "    test_accuracy=model.score(x_test,y_test)\n",
        "        \n",
        "    MAE=metrics.mean_absolute_error(y_test, y_pred_test)\n",
        "    MSE=metrics.mean_squared_error(y_test, y_pred_test)\n",
        "    RMSE=math.sqrt(MSE)\n",
        "    MAPE=mape(y_test, y_pred_test)\n",
        "    Rsquare=metrics.r2_score(y_test, y_pred_test)\n",
        "        \n",
        "        \n",
        "    #Inserting in dataframe\n",
        "    df.loc[i,\"Model_Name\"]=model.__class__.__name__\n",
        "    df.loc[i,\"MAE\"]=round(MAE,3)\n",
        "    df.loc[i,\"MSE\"]=round(MSE,3)\n",
        "    df.loc[i,\"RMSE\"]=round(RMSE,3)\n",
        "    df.loc[i,\"MAPE\"]=round(MAPE,3)\n",
        "    df.loc[i,\"Rsquare\"]=round(Rsquare,3)\n",
        "        \n",
        "    i+=1\n",
        "    \n",
        "  #Sorting values by accuracy\n",
        "  df.sort_values(by=['Rsquare'],ascending=False,inplace=True)\n",
        "    \n",
        "  return df"
      ],
      "metadata": {
        "id": "fVqli_e4VBWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_report=model_score(x_train,y_train,x_test,y_test)\n",
        "final_report"
      ],
      "metadata": {
        "id": "9au4iCrzVBTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am choosing XG boost as my final prediction model. While the other models have also performed well, the R square score of most model were around 0.80-0.85. The R-square score for xg boost is by far the best with 0.991, with both test and training evaulation having similar score(which points that there is no overfitting). If we will look closely on the graph, XG Boost captures the data trend very closely even on around the corners. The other models were failing to catch the trend on the corners which were decreases there score."
      ],
      "metadata": {
        "id": "yEF4HYFHWEuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain the model which you have used and the feature importance using any model explainability tool?\n",
        "\n",
        "Gradient boosting is a supervised learning algorithm, which attempts to accurately predict a target variable by combining the estimates of a set of simpler, weaker models. XG boost is simply an open source implementation of gradient boosted trees algorithm, which combines multiple weak learner. The weak learners are multiple regression trees.\n",
        "\n",
        "One of the key features of XGBoost is its efficient handling of missing values, which allows it to handle real-world data with missing values without requiring significant pre-processing. Additionally, XGBoost has built-in support for parallel processing, making it possible to train models on large datasets in a reasonable amount of time."
      ],
      "metadata": {
        "id": "tsOaoVO3WJsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I recieved data of open, high , low and close price of YES BANK stock price. I performed various teasks on data like visualization, data transformation and have build 5 different machine learning model to pridict our target variable i.e. close price. In the end I choosed xg boost to achieve our task as it provided the highest r2 score. With this model, we will be able to accurately predict the close price and hence the company can make profit during trading hence positive buisness developement."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}