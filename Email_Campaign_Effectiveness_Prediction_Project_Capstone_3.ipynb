{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navinsinghdo/capstone/blob/main/Email_Campaign_Effectiveness_Prediction_Project_Capstone_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email Marketing can be defined as a marketing technique in which businesses stay connected with their customers through emails, making them aware about their new products, updates, important notices related to the products they are using. My problem statement was to use different features of email like email campaign, past communications, etc (from provided data frame) and predict how the cx will response for email. The cx can neglect the email, read it or acknowledge the email. The more the cx acknowledge the email, the sucessful the campaign is. I recieved a data frame with the following column:\n",
        "\n",
        "Email Id - It contains the email id's of the customers/individuals\n",
        "Email Type - There are two categories 1 and 2. We can think of them as marketing emails or important updates, notices like emails regarding the business.\n",
        "Subject Hotness Score - It is the email's subject's score on the basis of how good and effective the content is.\n",
        "Email Source - It represents the source of the email like sales and marketing or important admin mails related to the product.\n",
        "Email Campaign Type - The campaign type of the email.\n",
        "Total Past Communications - This column contains the total previous mails from the same source, the number of communications had.\n",
        "Customer Location - Contains demographical data of the customer, the location where the customer resides.\n",
        "Time Email sent Category - It has three categories 1,2 and 3; the time of the day when the email was sent, we can think of it as morning, evening and night time slots.\n",
        "Word Count - The number of words contained in the email.\n",
        "Total links - Number of links in the email.\n",
        "Total Images - Number of images in the email.\n",
        "Email Status - Our target variable which contains whether the mail was ignored, read, acknowledged by the reader.\n",
        "\n",
        "I started my analysis with checking null values, I filled them up with mean and mode according to it's distribution. During EDA, I also saw the distribution of email neglected, read and acknowledged w.r.t. different continous and categorical features(as mentioned above and in detail in colab). I also plotted detailed graph of distribution.\n",
        "\n",
        "Further, in next section, I analyzed the corelation between different different features. I also checked the VIF, used IQR stat technique to check outliers and did one-hot encoding before model building as this problem had a number of categorical variable.\n",
        "\n",
        "In the model building part, I checked that the data was highly embalanced. I used random undersampling and SMOTE technique to create different train data set for different model and checked the model scores for them individually. XGB performed the best, thus I accepted it final model."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the small to medium business owners are making effective use of Gmail-based Email marketing Strategies for offline targeting of converting their prospective customers into leads so that they stay with them in Business. The main objective is to create a machine learning model to characterize the mail and track the mail that is ignored; read; acknowledged by the reader. Data columns are self-explanatory.\n",
        "\n",
        "Email marketing allows businesses to build relationships with leads, new customers and past customers. It's a way to communicate directly to the customers in their inbox, at a time that is convenient for them. With the right messaging tone and strategies, emails are one of the most important marketing channels."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "plt.rcParams.update({'figure.figsize':(8,5),'figure.dpi':100})\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, roc_auc_score, f1_score, recall_score,roc_curve, classification_report"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/AlmaBetter/email_campaign.csv')"
      ],
      "metadata": {
        "id": "zR5MdKw2gR07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "import missingno as msno\n",
        "msno.bar(df)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data base contains details of different email where the company have target email marketing, and tracked report if the email was open, acknowledged or simply neglected. It also have some other information, like location, past communication, etc. in columns with details below in understanding variable section.\n",
        "\n",
        "Our email campaign dataset have 68353 observations and 12 features. Clearly Email_Status is our target variable.\n",
        "\n",
        "It have no duplicates, but have a number of NAN if different columns which I will handle in later section."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email Id - It contains the email id's of the customers/individuals\n",
        "\n",
        "Email Type - There are two categories 1 and 2. We can think of them as marketing emails or important updates, notices like emails regarding the business.\n",
        "\n",
        "Subject Hotness Score - It is the email's subject's score on the basis of how good and effective the content is.\n",
        "\n",
        "Email Source - It represents the source of the email like sales and marketing or important admin mails related to the product.\n",
        "\n",
        "Email Campaign Type - The campaign type of the email.\n",
        "\n",
        "Total Past Communications- This column contains the total previous mails from the same source, the number of communications had.\n",
        "\n",
        "Customer Location- Contains demographical data of the customer, the location where the customer resides.\n",
        "\n",
        "Time Email sent Category - It has three categories 1,2 and 3; the time of the day when the email was sent, we can think of it as morning, evening and night time slots.\n",
        "\n",
        "Word Count - The number of words contained in the email.\n",
        "\n",
        "Total links - Number of links in the email.\n",
        "\n",
        "Total Images - Number of images in the email.\n",
        "\n",
        "Email Status - Our target variable which contains whether the mail was ignored, read, acknowledged by the reader."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am not doing any manipulation in data wrangling section, instead I have decided to do data cleaning, structuring, etc. in Feature engineering and data pre processing section, after vizualization."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1\n",
        "\n",
        "For categorical variables"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "#Writing a loop to plot all categorical variable.\n",
        "categorical_var = ['Email_Type','Email_Source_Type','Customer_Location','Email_Campaign_Type','Time_Email_sent_Category']\n",
        "Target_var = ['Email_Status']\n",
        "\n",
        "for i,value in enumerate(categorical_var):\n",
        "  ax = sns.countplot(x=df[value], hue=df[Target_var[0]])\n",
        "  unique = len([x for x in df[value].unique() if x==x])\n",
        "  bars = ax.patches\n",
        "  for i in range(unique):\n",
        "      catbars=bars[i:][::unique]\n",
        "      #get height\n",
        "      total = sum([x.get_height() for x in catbars])\n",
        "      #print percentage\n",
        "      for bar in catbars:\n",
        "        ax.text(bar.get_x()+bar.get_width()/2.,\n",
        "                    bar.get_height(),\n",
        "                    f'{bar.get_height()/total:.0%}',\n",
        "                    ha=\"center\",va=\"bottom\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we need to count and plot(distribution for categorical variable), thus seaborn count plot is the best option."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "Email type 1 seems to be sent in much higher number, but overall the ration of ignored, read , acknoweldge seems to be the same in graph.\n",
        "Email source shows very similar pattern.\n",
        "In the location graph again, the ratio seems quite similar, except for location g. (similar to hypothesis made earlier).\n",
        "Campaign 1 have a very high % of email read, while campaign 3 have high % of email acknowledged. Campaign 2 have too many emails ignored.\n",
        "There are much more number of email send in time '2'. Assuming that 1 is morning, 2 is working hours and 3 is night. People are usually more available during working hrs to open mail, thus it makes more sense as well."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2\n",
        "\n",
        "For continuous variables"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "#Making a loop to plot all continous variable. \n",
        "\n",
        "cont_var = ['Total_Past_Communications' , 'Total_Links', 'Total_Images' ,'Word_Count' , 'Subject_Hotness_Score']\n",
        "\n",
        "for column in cont_var:\n",
        "  az = sns.distplot( x = df[column] , hist = True)\n",
        "  plt.title(f'Plot for {column}')\n",
        "  plt.ylabel(column)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the distribution in continous variable, distplot in seaborn is best option."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word count have a normal looking distribution, while Subject hotness is skewed towards right. All other graphs(for continous variable) were plotted earlier as well."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n",
        "\n",
        "Box Plot"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# Let's look into the box plot. \n",
        "\n",
        "for column in cont_var:\n",
        "  az = sns.boxplot(x = df['Email_Status'] , y = df[column])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see 5 number summary, boxplot is the best option."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "In case when more number of total communication is there with audience, the more emails gets read and acknowledge.\n",
        "Mean of number of links in ignored, read and acknowledge is similar.\n",
        "Ignored emails have more images.\n",
        "Ignored emails also have higher words.\n",
        "'3' email status have many outliers in subject hotness score plot."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4\n",
        "\n",
        "Correlation heatmap"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Correlation Heatmap visualization code\n",
        "#Plotting heat map. \n",
        "\n",
        "plt.figure( figsize = (20,10))\n",
        "sns.heatmap(df.corr() , cmap = sns.diverging_palette(20, 220, n=200) , annot = True)"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize and understand corelation between features, heatmaps are a good and easy method."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "\n",
        "Total past communication and email campaign types have positive corelation with with email status. Word count and subject hotness is -vely corelated.\n",
        "\n",
        "We can also see multicollinearity in many other columns as well, marked in green. Dealing with it in next sections."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5\n",
        "\n",
        "Pair Plot"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Pair Plot visualization code\n",
        "sns.pairplot(df)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot is a good way to visualize all the feature variation and relation with respect to each other as well as the general distribution."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "T9Ua4F7_khte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "pJOPpJZpkkLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling total past communication:"
      ],
      "metadata": {
        "id": "QbnvjE72ktmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(x = df['Total_Past_Communications'] , hist = True)"
      ],
      "metadata": {
        "id": "iFCC9ojJklHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot seems to be a normal distribution, thus deciding to fill NAN in this column with mean."
      ],
      "metadata": {
        "id": "Oa44iIDnk6OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Total_Past_Communications'].fillna(df['Total_Past_Communications'].mean() , inplace = True)"
      ],
      "metadata": {
        "id": "17egfCDoklED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling total links:"
      ],
      "metadata": {
        "id": "wMOUsMw6k_EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(x = df['Total_Links'] , hist = True)"
      ],
      "metadata": {
        "id": "zlN0WahFklBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is slighlt skewed to right, so using mode or median is better option to fill na.\n",
        "\n",
        "As this is a case of small numerical data, deciding to fill na with Mode."
      ],
      "metadata": {
        "id": "3BN5zB3ClMN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Total_Links'].fillna(df['Total_Links'].mode()[0] , inplace = True)"
      ],
      "metadata": {
        "id": "mtod6xP3lTqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling total images:"
      ],
      "metadata": {
        "id": "06vlsZFwlZIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(x = df['Total_Images'] , hist = True)"
      ],
      "metadata": {
        "id": "5SS4zTRDlmdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is highly skewed towards right, using mode again."
      ],
      "metadata": {
        "id": "mL1viJcdDKwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Total_Images'].fillna(df['Total_Images'].mode()[0] , inplace = True)"
      ],
      "metadata": {
        "id": "3_cuvoMzltb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "9gxEnRwHDSWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only \"Customer_Location\" have null values now. Earlier, during data visualization part, I have noticed that the different customer location have similar (almost same) ratio of 0,1,2 target email type. Thus, I am not considering it as a factor in out analysis"
      ],
      "metadata": {
        "id": "jIDsQ6WjEXC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total past communication: Replaced by mean.\n",
        "Total link: Replaced by mode.\n",
        "Total images: Repalced by mode."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "#Checking VIF.\n",
        "\n",
        "#Imporitng lib for vif\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Writing a function to calulcate VIF. \n",
        "\n",
        "def vif_calculator(df):\n",
        "  vif  =pd.DataFrame()\n",
        "  vif['Columns'] = df.columns\n",
        "  vif['VIF'] = [variance_inflation_factor(df.values , i) for i in range(0,df.shape[1])]\n",
        "  return vif\n",
        "     "
      ],
      "metadata": {
        "id": "TOdh_4pFE3QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting vif and DataFrame\n",
        "\n",
        "vif_df = vif_calculator(df[[i for i in df.describe().columns if i not in categorical_var + ['Email_Status']]])\n",
        "vif_df\n",
        "     "
      ],
      "metadata": {
        "id": "vLLhh-qqE3M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total links have a very high vif of 8. We have seen earlier that total links and total images are highly corelated thus we can either drop it or combine"
      ],
      "metadata": {
        "id": "3EQmHo2IFGRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's plot a scatter plot. \n",
        "\n",
        "sns.scatterplot( x = df['Total_Images'] , y = df['Total_Links'] , hue= df['Email_Status'])"
      ],
      "metadata": {
        "id": "6rdmbAokE3KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows in general a linear relation.\n",
        "\n",
        "I will try to combine the, and then check vif again"
      ],
      "metadata": {
        "id": "2wciORpzFQ9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Image_Link_Total'] = df['Total_Images'] + df['Total_Links']\n",
        "\n",
        "df.drop(['Total_Images' , 'Total_Links'] , inplace = True , axis =1)"
      ],
      "metadata": {
        "id": "Juziu3qNFSav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif_df = vif_calculator(df[[i for i in df.describe().columns if i not in categorical_var + ['Email_Status']]])\n",
        "\n",
        "vif_df"
      ],
      "metadata": {
        "id": "3fALc1z0FTaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vif scores are under 5 so multicollinearity is taken care of."
      ],
      "metadata": {
        "id": "nWqw_d1LFh_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature manipulation: I have added a new feature called image link total, it's done to handle multicollinearity"
      ],
      "metadata": {
        "id": "nM-z1Yx5FtQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Handling Outliers"
      ],
      "metadata": {
        "id": "xRHgM7wHGJdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers:"
      ],
      "metadata": {
        "id": "aEaNxrNXGRvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already observed that all cont. variables in the data have outliers( except word count as shown in box plot). As deleting data can potentially lead to information loss, I am going to see if deleting them will loose more than 5% of information or how much of outliers are in minority class."
      ],
      "metadata": {
        "id": "Idka46fiGVia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cont_var"
      ],
      "metadata": {
        "id": "YA5hiySEGd3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing word count (as no outliers here), total links and total imnages. Adding the new column created: Image link Total.\n",
        "cont_var.remove('Word_Count')\n",
        "cont_var.remove('Total_Links')\n",
        "cont_var.remove('Total_Images')\n",
        "cont_var.append('Image_Link_Total')"
      ],
      "metadata": {
        "id": "6aqxvwTPGi9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = {}\n",
        "for elem in cont_var:\n",
        "  q_75, q_25 = np.percentile(df.loc[:,elem],[75,25])\n",
        "  IQR_zone = q_75-q_25\n",
        "  max = q_75+(1.5*IQR_zone)\n",
        "  min = q_25-(1.5*IQR_zone)\n",
        "  outlier_list=[]\n",
        "  outlier_list=df.loc[df[elem] < min]['Email_Status'].tolist()\n",
        "  outlier_list.append(df.loc[df[elem] > max]['Email_Status'].tolist()) \n",
        "  outliers[elem]={}\n",
        "  for i in outlier_list[0]:\n",
        "      outliers[elem][i] = outliers[elem].get(i,0) + 1\n",
        "print(outliers)"
      ],
      "metadata": {
        "id": "y-7jCHVkGpgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Email_Status'].value_counts()"
      ],
      "metadata": {
        "id": "WygSvSyFGurH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating % of outliers in minority class. \n",
        "\n",
        "minority_outliers = 0  \n",
        "majority_outliers = 0\n",
        "for col in cont_var:\n",
        "  minority_outliers += outliers[col][1]\n",
        "  minority_outliers += outliers[col][2]\n",
        "  majority_outliers += outliers[col][0]\n",
        "\n",
        "total_min = df['Email_Status'].value_counts()[1] + df['Email_Status'].value_counts()[2]\n",
        "total_maj = df['Email_Status'].value_counts()[0]\n",
        "\n",
        "min_per = (minority_outliers/total_min)*100   #number of outliers in minority classes by total number minority classes\n",
        "maj_per = (majority_outliers/total_maj)*100  #number of outliers in majority class by total number of majority class\n",
        "total_out = ((minority_outliers+majority_outliers)/(total_min+total_maj))*100"
      ],
      "metadata": {
        "id": "c-F1Mbh3GuoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The percentage of outliers in minority classes is {min_per}')\n",
        "print(f'The percentage of outliers in majority class is {maj_per}')\n",
        "print(f'The percentage of total outliers are {total_out}')"
      ],
      "metadata": {
        "id": "oh2t4CKAGulr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More than 5% outliers lies in minority section thus, I won't drop it"
      ],
      "metadata": {
        "id": "5k1xbvYsGRsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping outliers in majority.\n",
        "\n",
        "for elem in cont_var:\n",
        "  q_low = df[elem].quantile(0.01)\n",
        "  q_hi  = df[elem].quantile(0.99)\n",
        "  df = df.drop(df[(df[elem] > q_hi) &  (df['Email_Status']==0)].index)\n",
        "  df = df.drop(df[(df[elem] < q_low) & (df['Email_Status']==0)].index)"
      ],
      "metadata": {
        "id": "NCzPvZH_HEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "yu5KkrLvHGmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aXoMPUD1GRpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Email_Status'].value_counts()"
      ],
      "metadata": {
        "id": "EyvuL4rTFTUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What all outlier treatment techniques have you used and why did you use those techniques?\n",
        "\n",
        "I have used IQR (Interquartile range) method to handle outlier"
      ],
      "metadata": {
        "id": "SsMp0HBkHZiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "WpSN_KmZHo0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is done to prevent biased nature of machine learning algorithms towards features with greater values and scale"
      ],
      "metadata": {
        "id": "vmUMTstAL-63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "#let's add back word count\n",
        "cont_var.append('Word_Count')"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_var"
      ],
      "metadata": {
        "id": "r4eNiN3eMJOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling of numerical variables\n",
        "for elem in cont_var:\n",
        "  df[elem] = (df[elem] - df[elem].mean()) / (df[elem].std())\n",
        "\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "bsAve1ctMN1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have applied z score here for feature scaling."
      ],
      "metadata": {
        "id": "SOzupWP8MVc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Categorical Encoding"
      ],
      "metadata": {
        "id": "2imdQG6tMc2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One hot encoding\n",
        "\n",
        "Converting the categorical labels as vector."
      ],
      "metadata": {
        "id": "G09VRZ01Mg3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I have already seen and decided that customer location don't play any role in out analysis, thus I am dropping them from from columns that needs to be one hot encoded. \n",
        "\n",
        "categorical_var.remove('Customer_Location')\n",
        "\n",
        "#Following features are going to be one hot encoded .\n",
        "\n",
        "categorical_var"
      ],
      "metadata": {
        "id": "7qIxRDcGMhXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dummy variables\n",
        "df = pd.get_dummies(df,columns=categorical_var)"
      ],
      "metadata": {
        "id": "aaB4lB8DMuYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Email type 2 and email source type 2 columns as they are in binary, thus no need for them. It wil;l help in keeping df smaller and make model run faster. \n",
        "\n",
        "df.drop('Email_Type_2',axis=1,inplace=True)\n",
        "df.drop('Email_Source_Type_2',axis=1,inplace=True)\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "nJAZs6BKMy2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "P4dg7XhuM2Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "Y04a4Sc7NjTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used one hot encoding. It transforms strings into numbers so that we can apply our Machine Learning algorithms without any problems.\n",
        "\n",
        "Getting target variable as last column in df."
      ],
      "metadata": {
        "id": "fbbMFqUdNkQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing and appending target.\n",
        "columns=list(df.columns)\n",
        "columns.remove('Email_Status')\n",
        "columns.append('Email_Status')\n",
        "df=df[columns]\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "uAKz4-EQNPmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As seen earlier, we have no use of Email Id and location, thus dropping them. \n",
        "\n",
        "df.drop(['Email_ID' , 'Customer_Location'] , axis = 1, inplace =True)\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "H-BWzTqANUnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "x = df.drop('Email_Status' , axis = 1)\n",
        "y = df['Email_Status']\n",
        "\n",
        "x_train, x_test , y_train , y_test = train_test_split(x , y , test_size = 0.20 , random_state = 1 , stratify =y)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am using the common splitting ratio of 80, 20 so that I can train the model on 80% of data and later test it on remaining 20% of unseen data."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First, let's see % of each class. \n",
        "\n",
        "ax = sns.countplot(x=df['Email_Status'])\n",
        "totals = []\n",
        "for i in ax.patches:\n",
        "    totals.append(i.get_height())\n",
        "\n",
        "total = sum(totals)\n",
        "\n",
        "for i in ax.patches:\n",
        "    ax.text(i.get_x() - .01, i.get_height() + .5, \\\n",
        "          str(round((i.get_height()/total)*100, 2))+'%', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xYk6EF0iOEbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's clear from above graph that there is a imbalance in data. The class inbalance favours un-opened emails, as said earlier. It's 79.96% of label."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Undersampling"
      ],
      "metadata": {
        "id": "PMjzlqXmOTeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing random undersampling at first. \n",
        "\n",
        "#Importing lib\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "631TvSS7OUYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ru = RandomUnderSampler(random_state = 1 , replacement = True)\n",
        "x_train_ru , y_train_ru = ru.fit_resample(x_train , y_train)"
      ],
      "metadata": {
        "id": "liBJb08QOcsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_ru.value_counts()"
      ],
      "metadata": {
        "id": "rlhVpLFYOhPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train_ru)"
      ],
      "metadata": {
        "id": "pqcfClndOg8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, all class have same number of data now.\n",
        "\n",
        "SMOTE"
      ],
      "metadata": {
        "id": "iDDN0R1IOp8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing SMOTE now. \n",
        "\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "toDJDMlGOrHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE()\n",
        "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "H4tyyWapOr9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_smote.value_counts()"
      ],
      "metadata": {
        "id": "8UkN3VeSO2uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train_smote)"
      ],
      "metadata": {
        "id": "jAJZs9P4O6zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, y_train of smote have a much bigger data set."
      ],
      "metadata": {
        "id": "l2Z5ieVZPA91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used 2 methods to handle imbalance in the data:\n",
        "\n",
        "Random undersampling: Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset.\n",
        "SMOTE: SMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n",
        "I am using both method, will later see which gives the best result.\n",
        "\n",
        "In case we neglect class imbalance, standard classifiers tend to be overwhelmed by the large classes and ignore the small ones.Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a function to run and compare different models."
      ],
      "metadata": {
        "id": "OzaESt5qQBqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Columns req. for model comparision Table. \n",
        "comparison_columns = ['Model_Name', 'Train_Accuracy', 'Train_Recall', 'Train_Precision', 'Train_F1score', 'Train_AUC' ,'Test_Accuracy', 'Test_Recall']"
      ],
      "metadata": {
        "id": "i7XTPeYnQCqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to evaluate model. \n",
        "\n",
        "def model_evaluation(model_name_RUS,model_name_SMOTE,model_var_ru, model_var_smote, x_train_ru, y_train_rus, x_train_smote, y_train_smote, X_test, y_test):\n",
        "\n",
        "\n",
        "  #Prediction by random unsampling. \n",
        "  y_pred_ru_train = model_var_ru.predict(x_train_ru)\n",
        "  y_pred_ru_test = model_var_ru.predict(x_test)\n",
        "  #Probablity\n",
        "  train_ru_proba = model_var_ru.predict_proba(x_train_ru)\n",
        "  test_ru_proba = model_var_ru.predict_proba(x_test)\n",
        "\n",
        "  #smote prediction and probability. \n",
        "  y_pred_smote_train = model_var_smote.predict(x_train_smote)\n",
        "  y_pred_smote_test = model_var_smote.predict(x_test)\n",
        "\n",
        "  train_smote_proba = model_var_smote.predict_proba(x_train_smote)\n",
        "  test_smote_proba = model_var_smote.predict_proba(x_test)\n",
        "\n",
        "  #Evaluation \n",
        "  #Accuracy RUS\n",
        "  accuracy_ru_train = accuracy_score(y_train_rus,y_pred_ru_train)\n",
        "  accuracy_ru_test = accuracy_score(y_test,y_pred_ru_test)\n",
        "  #Accuracy SMOTE\n",
        "  accuracy_smote_train = accuracy_score(y_train_smote,y_pred_smote_train)\n",
        "  accuracy_smote_test = accuracy_score(y_test,y_pred_smote_test)\n",
        "\n",
        "  #Confusion Matrix RUS\n",
        "  cm_ru_train = confusion_matrix(y_train_rus,y_pred_ru_train)\n",
        "  cm_ru_test = confusion_matrix(y_test,y_pred_ru_test)\n",
        "  #Confusion Matrix SMOTE\n",
        "  cm_smote_train = confusion_matrix(y_train_smote,y_pred_smote_train)\n",
        "  cm_smote_test = confusion_matrix(y_test,y_pred_smote_test)\n",
        "\n",
        "  #Recall RUS\n",
        "  train_recall_rus = recall_score(y_train_rus,y_pred_ru_train, average='weighted')\n",
        "  test_recall_rus = recall_score(y_test,y_pred_ru_test, average='weighted')\n",
        "  #Recall SMOTE\n",
        "  train_recall_smote = recall_score(y_train_smote,y_pred_smote_train, average='weighted')\n",
        "  test_recall_smote = recall_score(y_test,y_pred_smote_test, average='weighted')\n",
        "\n",
        "  #Precision RUS\n",
        "  train_precision_rus = precision_score(y_train_rus,y_pred_ru_train, average='weighted')\n",
        "  test_precision_rus = precision_score(y_test,y_pred_ru_test, average='weighted')\n",
        "  #Precision SMOTE\n",
        "  train_precision_smote = precision_score(y_train_smote,y_pred_smote_train, average='weighted')\n",
        "  test_precision_smote = precision_score(y_test,y_pred_smote_test, average='weighted')\n",
        "\n",
        "  #F1 Score RUS\n",
        "  train_f1_rus = f1_score(y_train_rus,y_pred_ru_train, average='weighted')\n",
        "  test_f1_rus = f1_score(y_test,y_pred_ru_test, average='weighted')\n",
        "  #F1 Score SMOTE\n",
        "  train_f1_smote = f1_score(y_train_smote,y_pred_smote_train, average='weighted')\n",
        "  test_f1_smote = f1_score(y_test,y_pred_smote_test, average='weighted')\n",
        "\n",
        "  #ROC-AUC RUS\n",
        "  train_auc_rus = roc_auc_score(y_train_rus,train_ru_proba,average='weighted',multi_class = 'ovr')\n",
        "  test_auc_rus = roc_auc_score(y_test,test_ru_proba,average='weighted',multi_class = 'ovr')\n",
        "  #ROC-AUC SMOTE\n",
        "  train_auc_smote = roc_auc_score(y_train_smote,train_smote_proba,average='weighted',multi_class = 'ovr')\n",
        "  test_auc_smote = roc_auc_score(y_test,test_smote_proba,average='weighted',multi_class = 'ovr')\n",
        "\n",
        "  #Visualising Results RUS\n",
        "  print(\"----- Evaluation on Random Undersampled data -----\" + str(model_name_RUS) + \"------\")\n",
        "  print(\"--------------Test data ---------------\\n\")\n",
        "  print(\"Confusion matrix \\n\")\n",
        "  print(cm_ru_test)\n",
        "  print(classification_report(y_test,y_pred_ru_test))\n",
        "\n",
        "  #create ROC curve\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  thresh ={}\n",
        "  no_of_class=3\n",
        "  for i in range(no_of_class):    \n",
        "      fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, test_ru_proba[:,i], pos_label=i)\n",
        "  plt.plot(fpr[0], tpr[0], linestyle='--',color='blue', label='Class 0 vs Others'+\"AUC=\"+str(test_auc_rus))\n",
        "  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Others'+\"AUC=\"+str(test_auc_rus))\n",
        "  plt.plot(fpr[2], tpr[2], linestyle='--',color='orange', label='Class 2 vs Others'+\"AUC=\"+str(test_auc_rus))\n",
        "  plt.title('Multiclass ROC curve of ' + str(model_name_RUS))\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Visualising Results SMOTE\n",
        "  print(\"----- Evaluation on SMOTE data -------\" + str(model_name_SMOTE) + '-----')\n",
        "  print(\"---------------Test data ---------------\\n\")\n",
        "  print(\"Confusion matrix \\n\")\n",
        "  print(cm_smote_test)\n",
        "  print(classification_report(y_test,y_pred_smote_test))\n",
        "\n",
        " \n",
        "  #create ROC curve\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  thresh ={}\n",
        "  no_of_class=3\n",
        "  for i in range(no_of_class):    \n",
        "      fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, test_smote_proba[:,i], pos_label=i)\n",
        "  plt.plot(fpr[0], tpr[0], linestyle='--',color='blue', label='Class 0 vs Others'+\" AUC=\"+str(test_auc_smote))\n",
        "  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Others'+\" AUC=\"+str(test_auc_smote))\n",
        "  plt.plot(fpr[2], tpr[2], linestyle='--',color='orange', label='Class 2 vs Others'+\" AUC=\"+str(test_auc_smote))\n",
        "  plt.title('Multiclass ROC curve of '+ str(model_name_SMOTE))\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  #Saving our results\n",
        "  global comparison_columns\n",
        "  metric_scores_rus = [model_name_RUS,accuracy_ru_train,train_recall_rus,train_precision_rus,train_f1_rus,train_auc_rus,accuracy_ru_test,test_recall_rus,test_precision_rus,test_f1_rus,test_auc_rus]\n",
        "  final_dict_rus = dict(zip(comparison_columns,metric_scores_rus))\n",
        "\n",
        "  metric_scores_smote = [model_name_SMOTE,accuracy_smote_train,train_recall_smote,train_precision_smote,train_f1_smote,train_auc_smote,accuracy_smote_test,test_recall_smote,test_precision_smote,test_f1_smote,test_auc_smote]\n",
        "  final_dict_smote = dict(zip(comparison_columns,metric_scores_smote))\n",
        "\n",
        "  dict_list = [final_dict_rus, final_dict_smote]\n",
        "  return dict_list"
      ],
      "metadata": {
        "id": "uloKQMXOQTSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating comparision table(function)\n",
        "final_list = []\n",
        "def add_eval_to_final_df(dict_list):\n",
        "  global final_list\n",
        "  for elem in dict_list:\n",
        "    final_list.append(elem)\n",
        "  global comparison_df\n",
        "  comparison_df = pd.DataFrame(final_list, columns= comparison_columns)"
      ],
      "metadata": {
        "id": "ar8rR8owQcrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1\n",
        "\n",
        "Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "u2hrVojgQn9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelling for random unsampling\n",
        "logistic_ru = LogisticRegression(class_weight='balanced',multi_class='multinomial', solver='lbfgs')\n",
        "logistic_ru.fit(x_train_ru, y_train_ru)"
      ],
      "metadata": {
        "id": "mj1-UkFIQwbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelling for smote\n",
        "logistic_smote = LogisticRegression(class_weight='balanced',multi_class='multinomial', solver='lbfgs')\n",
        "logistic_smote.fit(x_train_smote, y_train_smote)"
      ],
      "metadata": {
        "id": "GIcHWkzuQ0ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression is a data analysis technique that uses mathematics to find the relationships between two data factors. It then uses this relationship to predict the value of one of those factors based on the other. The prediction usually has a finite number of outcomes, like yes or no and using the same technique we also make multinomial LR to predict multi class problem ( as we did in this case)"
      ],
      "metadata": {
        "id": "o2QtqYFMQ_Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "#Evaluating LR model. \n",
        "\n",
        "logistic_reg_eval = model_evaluation('LogisticReg RU','LogisticReg SMOTE',logistic_ru, logistic_smote, x_train_ru, y_train_ru, x_train_smote, y_train_smote, x_test, y_test)\n",
        "logistic_reg_eval"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding in final DF\n",
        "add_eval_to_final_df(logistic_reg_eval)\n",
        "\n",
        "comparison_df"
      ],
      "metadata": {
        "id": "plU-FkP3RQ-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: It measures how many observations, both positive and negative, were correctly classified.\n",
        "F1 score: Simply put, it combines precision and recall into one metric by calculating the harmonic mean between those two.\n",
        "F1 score combines both recall and precision, thus from here on, we will keep a eye primarily on F1 score and accuracy"
      ],
      "metadata": {
        "id": "dbs8yLZiRWgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "\n",
        "Decision Tree"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "PTX-84BgRgTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For random unsampling\n",
        "DT_ru = DecisionTreeClassifier()\n",
        "DT_ru.fit(x_train_ru,y_train_ru)"
      ],
      "metadata": {
        "id": "EOZHG1BSRhiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for SMOTE\n",
        "DT_smote = DecisionTreeClassifier()\n",
        "DT_smote.fit(x_train_smote,y_train_smote)"
      ],
      "metadata": {
        "id": "FuYDf2LlRhYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes."
      ],
      "metadata": {
        "id": "RQsctL5PTK3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "DT_eval = model_evaluation('Decision Tree RU', 'Decision Tree SMOTE', DT_ru, DT_smote, x_train_ru, y_train_ru, x_train_smote, y_train_smote, x_test, y_test)\n",
        "DT_eval"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_eval_to_final_df(DT_eval)"
      ],
      "metadata": {
        "id": "3g1vWUpZTb_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df"
      ],
      "metadata": {
        "id": "UZG_zJDvTdc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: DT are preforming real good in training, but it's accuracy is bad in testing. Specially testing accuracy is very poor in Random unsampling. It points towards overfitting."
      ],
      "metadata": {
        "id": "-bV68frlTpNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3\n",
        "\n",
        "Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "p_1JZexJUqaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For random unsampling\n",
        "rf_ru = RandomForestClassifier(random_state=42, max_depth=5, n_estimators=100, oob_score=True)\n",
        "rf_ru.fit(x_train_ru,y_train_ru)"
      ],
      "metadata": {
        "id": "uil1YqOgUqPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For SMOTE\n",
        "rf_smote = RandomForestClassifier(random_state=42, max_depth=5, n_estimators=100, oob_score=True)\n",
        "rf_smote.fit(x_train_smote,y_train_smote)"
      ],
      "metadata": {
        "id": "Sg4VDPOtUqCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest combines the output of multiple decision trees to reach a single result."
      ],
      "metadata": {
        "id": "aBcraMeSU9iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "#Evaluation of Random forest\n",
        "rf_eval = model_evaluation('Random Forest RU', 'Random Forest SMOTE', rf_ru, rf_smote, x_train_ru, y_train_ru, x_train_smote, y_train_smote, x_test, y_test)\n",
        "rf_eval"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_eval_to_final_df(rf_eval)"
      ],
      "metadata": {
        "id": "CT4bKT7gVMw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df"
      ],
      "metadata": {
        "id": "gGIVm10kVO40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Although there is no overfitting here, but decision tree in SMOTE is performing better(slightly)."
      ],
      "metadata": {
        "id": "n7NAYwdDVYI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest hypertuning"
      ],
      "metadata": {
        "id": "c1A9wbNgVcma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)"
      ],
      "metadata": {
        "id": "4NvVxJ0SVd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting different parameter\n",
        "parameter = {'max_depth': [3,5,10,20],'min_samples_leaf': [5,10,20,50,100],'n_estimators': [10,25,30,50,100,200]}"
      ],
      "metadata": {
        "id": "OsUcuo2kVe2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running grid search to run and identify best parameter. \n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameter, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")"
      ],
      "metadata": {
        "id": "-rgXdbtkVerc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting in Random unsampling\n",
        "grid_search.fit(x_train_ru,y_train_ru)"
      ],
      "metadata": {
        "id": "qorU6p6OVen9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stroing best model. \n",
        "rf_tuned_ru = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "FSRkAccIVelr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running grid search to run and identify best parameter. \n",
        "grid_search_smote = GridSearchCV(estimator=rf, param_grid=parameter, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")"
      ],
      "metadata": {
        "id": "js3IQTTxWR2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing best model\n",
        "rf_tuned_smote = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "kDvQAjASWePB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used gridsearchcv to find the best parameter."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "rf_tuned_eval = model_evaluation('RandomF Tuned RU', 'RandomF Tuned SMOTE', rf_tuned_ru, rf_tuned_smote,x_train_ru, y_train_ru, x_train_smote, y_train_smote, x_test, y_test)\n",
        "rf_tuned_eval"
      ],
      "metadata": {
        "id": "-qGlVw0EWrrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_eval_to_final_df(rf_tuned_eval)"
      ],
      "metadata": {
        "id": "iVWugm9RWxvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although there have been some improvement in training accuracy, there is no imporvement in test accuracy. The f1 score is also following a similar trend."
      ],
      "metadata": {
        "id": "-9iZR0aWW2eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Model-4\n",
        "\n",
        "XGB Boost"
      ],
      "metadata": {
        "id": "UuNYmUbhYEuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing lib.\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "XNCINGFpYrqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For SMOTE\n",
        "xgb_smote = XGBClassifier(n_estimators=100,max_depth=12,min_samples_leaf=20,min_samples_split=30)\n",
        "xgb_smote.fit(x_train_smote,y_train_smote)"
      ],
      "metadata": {
        "id": "H2EKBWHljBj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For RUS\n",
        "xgb_rus = XGBClassifier(n_estimators=100,max_depth=12,min_samples_leaf=20,min_samples_split=30)\n",
        "xgb_rus.fit(x_train_ru,y_train_ru)"
      ],
      "metadata": {
        "id": "eQ4GNriSYSn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "KcqsdJD4ZBlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost is a popular and efficient open-source implementation of the gradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm, which attempts to accurately predict a target variable by combining the estimates of a set of simpler, weaker models."
      ],
      "metadata": {
        "id": "xaoLl6NvZFSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_eval = model_evaluation('XGB RUS', 'XGB SMOTE',xgb_rus, xgb_smote,x_train_ru, y_train_ru, x_train_smote, y_train_smote, x_test, y_test)\n",
        "xgb_eval\n",
        "     "
      ],
      "metadata": {
        "id": "_ZYqtmrIjrQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_eval_to_final_df(xgb_eval)"
      ],
      "metadata": {
        "id": "BdrxkOUVZT3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df"
      ],
      "metadata": {
        "id": "wkLCe5HfZU6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "MqwD8FJZZfiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project of multi class classification model, I have decided to choose both accuracy and F1 score. F1 score combines both precision and recall. Our target is to identify and correctly predict email that are going to be read and acknowledge by our audience, the better we can identiy the pattern, the better it wil be for buisness. Both accuracy and f1 score is measuring how good our model is doing in predicting the target."
      ],
      "metadata": {
        "id": "p0BitxdxZi7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "Bp7hMLtZZnpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df.sort_values(by=[\"Train_F1score\",'Train_AUC'], ascending=(False,False), inplace = True, ignore_index = True)\n",
        "comparison_df"
      ],
      "metadata": {
        "id": "UyzAl7iYkEJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following is the comparision of different models and it's F1 score."
      ],
      "metadata": {
        "id": "Zb3M5F4gZ1s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(y='Model_Name', x = 'Train_F1score' ,data = comparison_df)"
      ],
      "metadata": {
        "id": "RMVDMZ3LZ2pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following is the comparision of different models and it's AUC"
      ],
      "metadata": {
        "id": "Arh4ls6PZ-SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(y='Model_Name', x ='Train_AUC' , data = comparison_df)"
      ],
      "metadata": {
        "id": "K4_wpjl_Z_El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking feature importance by XGB:\n",
        "\n",
        "feature_imp_df = pd.DataFrame({\"Variable\": x_train_smote.columns,\"Importance\": xgb_smote.feature_importances_})\n",
        "feature_imp_df.sort_values(by=\"Importance\", ascending=False, inplace = True)"
      ],
      "metadata": {
        "id": "wIOVavyvdbvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp_df"
      ],
      "metadata": {
        "id": "teAKekp2ddVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x=feature_imp_df['Importance'],y= feature_imp_df['Variable'])  #Checking graph."
      ],
      "metadata": {
        "id": "tUmbrA3OdnVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I recieved data regarding email campaign which included different columns like campaign time, location, id, email source, etc. My task was to identify email status, if it was neglected, read or acknowledged, hence generating positive buisness impact. I have performed a series of visualization, where I visualized distribution of data, corelation and how they varry. I also performed data cleaning, one hot encoding, scaling, etc. As the target data was highly unbalanced, I used undersampling and oversampling method as well. I build a series of classification models and calculated there scores. I focused on F1 score and accuracy. In the end I choosed XG boost model to categories our target variable, due to it's high score.\n",
        "\n",
        "In following list, I am mentioning various important observation as well as sugestion to generate positve buisness growth.\n",
        "\n",
        "In campaign type 3, fewer emails were send, but it was highly read and even acknowledged. In campaign type 2, high numbers of email were read. Campaign 2 have highest number of email send but mostly neglected.\n",
        "Suggestion: Send more email in type 1 and 3. Work to improve email type 2.\n",
        "\n",
        "The cx with higher past communication gave much better response.\n",
        "Suggestion: Building a good relation with cx is essential for campaign sucess, company can send more emails on regular basis.\n",
        "\n",
        "Emails with higher number of words were more frequently neglected. Also, cx neglected emails with more images. The total image link shuld also be moderate and reasonable.\n",
        "Suggestion: The content team should focus on making the email precise and short. It should also contain less image or the graphics team much work on makes images more intresting.\n",
        "\n",
        "The cx location and time doesnt seem to have much or any effect on campaign.\n",
        "Several ML models were made, and the accuracy scores for train and test is mentioned in above data frame. XGB performed the best, with F1 score(test) of 0.77."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}